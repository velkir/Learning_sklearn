{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP9haz1ZCXsojIqy0h2lSKD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Exercise 21**\n","\n","The IRIS dataset was loaded into *data* and *target* variables. These datasets was spitted into the training set (*data_train, target_train*) and the test set (*data_test, target_test*).\n","\n","Create a logistic regression model (set `max_iter=1000`) using *LogisticRegression*  from the *scikit-learn* package. Fit the model on the train set and then evaluate the model on the test set.\n","\n","In response, print the accuracy of the model on the test set as shown below.\n","\n","**Expected result:**\n","`Accuracy: 0.9333`\n","\n","[Solution 21](https://www.notion.so/Solution-21-c33ae2fa81ae486db91bfc0f8a6af914?pvs=21)"],"metadata":{"id":"FuqUjWSBjbol"}},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-NEQHUUjZ57","executionInfo":{"status":"ok","timestamp":1714828806227,"user_tz":-120,"elapsed":2,"user":{"displayName":"Cabuxo","userId":"03926967791650024818"}},"outputId":"b8ec9240-4c76-4b5f-e3f3-7a385784e381"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.2.2\n","Accuracy: 0.9333\n"]}],"source":["# !pip install -U scikit-learn\n","\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","\n","print(sklearn.__version__)\n","\n","data, target = datasets.load_iris(return_X_y=True)\n","\n","data_train, data_test, target_train, target_test = sklearn.model_selection.train_test_split(\n","    data,\n","    target,\n","    test_size=0.3,\n","    random_state=20)\n","\n","model = LogisticRegression(max_iter=1000).fit(data_train, target_train)\n","\n","accuracy = model.score(data_test, target_test)\n","print(f\"Accuracy: {accuracy:.4f}\")"]},{"cell_type":"markdown","source":["**Exercise 22**\n","\n","The IRIS dataset was loaded into *data* and *target* variables. These datasets was spitted into the training set (*data_train, target_train*) and the test set (*data_test, target_test*).\n","\n","The logistic regression model was built using *LogisticRegression* from the *scikit-learn* package.\n","\n","Using this model make a prediction on the test set and assign to *target_pred* variable.\n","\n","In response, print the *target_pred* variable to the console.\n","\n","**Expected result:**\n","\n","`[0 1 1 2 1 1 2 0 2 0 2 1 1 0 0 2 0 1 2 1 1 2 2 0 1 1 1 0 2 1 1 1 0 0 0 1 1 0 1 2 1 2 0 1 1]`\n","\n","[Solution 22](https://www.notion.so/Solution-22-69d78dcc02c64584a3abe5fc00ec7e62?pvs=21)"],"metadata":{"id":"3eywR80qjpNs"}},{"cell_type":"code","source":["from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","\n","print(sklearn.__version__)\n","\n","data, target = datasets.load_iris(return_X_y=True)\n","\n","data_train, data_test, target_train, target_test = sklearn.model_selection.train_test_split(\n","    data,\n","    target,\n","    test_size=0.3,\n","    random_state=20)\n","\n","model = LogisticRegression(max_iter=1000).fit(data_train, target_train)\n","\n","target_pred = model.predict(data_test)\n","print(target_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCT23Oxljqmb","executionInfo":{"status":"ok","timestamp":1714828907335,"user_tz":-120,"elapsed":215,"user":{"displayName":"Cabuxo","userId":"03926967791650024818"}},"outputId":"fcbffd44-d9fd-4bab-919c-dd38bcf5ea3e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["1.2.2\n","[0 1 1 2 1 1 2 0 2 0 2 1 1 0 0 2 0 1 2 1 1 2 2 0 1 1 1 0 2 1 1 1 0 0 0 1 1\n"," 0 1 2 1 2 0 1 1]\n"]}]},{"cell_type":"markdown","source":["**Exercise 23**\n","\n","The IRIS dataset was loaded into *data* and *target* variables. These datasets was spitted into the training set (*data_train, target_train*) and the test set (*data_test, target_test*). The logistic regression model was built using the *scikit-learn* package.\n","\n","Predictions on the test set was assigned to the variable *target_pred*.\n","\n","Using *scikit-learn* package specify the confusion matrix (`confusion_matrix()`) and print it to the console as shown below.\n","\n","**Expected result:**\n","\n"," `[[13  0  0]\n","   [ 0 18  0]\n","   [ 0  3 11]]`\n","\n","[Solution 23](https://www.notion.so/Solution-23-6687f4b1a9884d5ab7b58ce4110aca35?pvs=21)"],"metadata":{"id":"fpsB6w0sjt4n"}},{"cell_type":"code","source":["import sklearn\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","\n","data, target = sklearn.datasets.load_iris(return_X_y=True)\n","\n","data_train, data_test, target_train, target_test = sklearn.model_selection.train_test_split(\n","    data,\n","    target,\n","    test_size=0.3,\n","    random_state=20)\n","\n","model = LogisticRegression(max_iter=1000).fit(data_train, target_train)\n","target_pred = model.predict(data_test)\n","\n","confusion_matrix(target_test, target_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z54pAFl4jup7","executionInfo":{"status":"ok","timestamp":1714828764346,"user_tz":-120,"elapsed":2,"user":{"displayName":"Cabuxo","userId":"03926967791650024818"}},"outputId":"7ffc0cba-42e4-4c10-8ab7-675e8be7f984"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[13,  0,  0],\n","       [ 0, 18,  0],\n","       [ 0,  3, 11]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["**Exercise 24**\n","\n","The IRIS dataset was loaded into *data* and *target* variables. These datasets was spitted into the training set (*data_train, target_train*) and the test set (*data_test, target_test*). The logistic regression model was built using the *scikit-learn* package.\n","\n","Predictions on the test set was assigned to the variable *target_pred*.\n","\n","Print the classification report using the `classification_report()` function from the *scikit-learn* package to the console.\n","\n","**Expected result:**\n","\n","```python\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       0.86      1.00      0.92        18\n","           2       1.00      0.79      0.88        14\n","\n","    accuracy                           0.93        45\n","   macro avg       0.95      0.93      0.93        45\n","weighted avg       0.94      0.93      0.93        45\n","```\n","\n","[Solution 24](https://www.notion.so/Solution-24-af704f0aa04741a99a92e0a21cdfdeeb?pvs=21)"],"metadata":{"id":"SbmzY5ROju6x"}},{"cell_type":"code","source":["import sklearn\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","\n","data, target = datasets.load_iris(return_X_y=True)\n","\n","data_train, data_test, target_train, target_test = train_test_split(\n","    data,\n","    target,\n","    test_size=0.3,\n","    random_state=20)\n","\n","model = LogisticRegression(max_iter=1000)\n","model.fit(data_train, target_train)\n","\n","target_pred = model.predict(data_test)\n","\n","report = sklearn.metrics.classification_report(target_test, target_pred)\n","print(report)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyNSkxjwxLo7","executionInfo":{"status":"ok","timestamp":1714829219875,"user_tz":-120,"elapsed":196,"user":{"displayName":"Cabuxo","userId":"03926967791650024818"}},"outputId":"c637354b-9947-4eb1-a3e9-085d7266faa6"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       0.86      1.00      0.92        18\n","           2       1.00      0.79      0.88        14\n","\n","    accuracy                           0.93        45\n","   macro avg       0.95      0.93      0.93        45\n","weighted avg       0.94      0.93      0.93        45\n","\n"]}]},{"cell_type":"markdown","source":["**Exercise 25**\n","\n","The *df* *DataFrame* is given below:\n","\n","```python\n","  size  color  gender  price  weight bought\n","0   XL    red  female  199.0     500    yes\n","1    L  green    male   89.0     450     no\n","2    M   blue    male   99.0     300    yes\n","3    L  green  female  129.0     380     no\n","4    M    red  female   79.0     410    yes\n","```\n","\n","Using the *LabelEncoder* class from the *scikit-learn* package encode target variable - *bought* as shown below and assign the result to the *df DataFrame*.\n","\n","In response, print the *df DataFrame* to the console.\n","\n","**Expected result:**\n","\n","```python\n","  size  color  gender  price  weight  bought\n","0   XL    red  female  199.0   500.0       1\n","1    L  green    male   89.0   450.0       0\n","2    M   blue    male   99.0   300.0       1\n","3    L  green  female  129.0   380.0       0\n","4    M    red  female   79.0   410.0       1\n","```\n","\n","[Solution 25](https://www.notion.so/Solution-25-f0fcaf39757043f18c1aebf14ca94741?pvs=21)"],"metadata":{"id":"pCs5KpQijz4f"}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","import pandas as pd\n","\n","data = {\n","    'size': ['XL', 'L', 'M', 'L', 'M'],\n","    'color': ['red', 'green', 'blue', 'green', 'red'],\n","    'gender': ['female', 'male', 'male', 'female', 'female'],\n","    'price': [199.0, 89.0, 99.0, 129.0, 79.0],\n","    'weight': [500, 450, 300, 380, 410],\n","    'bought': ['yes', 'no', 'yes', 'no', 'yes']\n","}\n","\n","df = pd.DataFrame(data)\n","df[\"bought\"] = LabelEncoder().fit_transform(data[\"bought\"])\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"wbSLRe4Vj0TG","executionInfo":{"status":"ok","timestamp":1714830239861,"user_tz":-120,"elapsed":354,"user":{"displayName":"Cabuxo","userId":"03926967791650024818"}},"outputId":"a27c61f1-5f46-4b5f-ec7e-bf0769a702cd"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  size  color  gender  price  weight  bought\n","0   XL    red  female  199.0     500       1\n","1    L  green    male   89.0     450       0\n","2    M   blue    male   99.0     300       1\n","3    L  green  female  129.0     380       0\n","4    M    red  female   79.0     410       1"],"text/html":["\n","  <div id=\"df-68b40a36-7b0d-4f75-a70b-6814852c50af\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>size</th>\n","      <th>color</th>\n","      <th>gender</th>\n","      <th>price</th>\n","      <th>weight</th>\n","      <th>bought</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>XL</td>\n","      <td>red</td>\n","      <td>female</td>\n","      <td>199.0</td>\n","      <td>500</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>L</td>\n","      <td>green</td>\n","      <td>male</td>\n","      <td>89.0</td>\n","      <td>450</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>M</td>\n","      <td>blue</td>\n","      <td>male</td>\n","      <td>99.0</td>\n","      <td>300</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>L</td>\n","      <td>green</td>\n","      <td>female</td>\n","      <td>129.0</td>\n","      <td>380</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>M</td>\n","      <td>red</td>\n","      <td>female</td>\n","      <td>79.0</td>\n","      <td>410</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68b40a36-7b0d-4f75-a70b-6814852c50af')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-68b40a36-7b0d-4f75-a70b-6814852c50af button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-68b40a36-7b0d-4f75-a70b-6814852c50af');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ff96245b-af6e-4254-90f1-896d0584823e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff96245b-af6e-4254-90f1-896d0584823e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ff96245b-af6e-4254-90f1-896d0584823e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"size\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"XL\",\n          \"L\",\n          \"M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"color\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"red\",\n          \"green\",\n          \"blue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male\",\n          \"female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 48.47679857416329,\n        \"min\": 79.0,\n        \"max\": 199.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          89.0,\n          79.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 75,\n        \"min\": 300,\n        \"max\": 500,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          450,\n          410\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bought\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["**Exercise 26**\n","\n","The *df* *DataFrame* is given below:\n","\n","```python\n","  size  color  gender  price  weight bought\n","0   XL    red  female  199.0     500    yes\n","1    L  green    male   89.0     450     no\n","2    M   blue    male   99.0     300    yes\n","3    L  green  female  129.0     380     no\n","4    M    red  female   79.0     410    yes\n","```\n","\n","Using the *OneHotEncoder* from the *scikit-learn* package, encode the *size* column as a one-hot numeric array. (set the parameter `sparse=False`).\n","\n","In response, print the encoded *size* column to the console (don't assign changes to the *df DataFrame*). Also print the encoding categories to the console as shown below.\n","\n","**Expected result:**\n","\n","```python\n","[[0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]]\n","[array(['L', 'M', 'XL'], dtype=object)]\n","```\n","\n","[Solution 26](https://www.notion.so/Solution-26-a95eeb7ab9ac42e88c91afdf3674209b?pvs=21)"],"metadata":{"id":"9LdPzLU6j5wK"}},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","import pandas as pd\n","\n","data = {\n","    'size': ['XL', 'L', 'M', 'L', 'M'],\n","    'color': ['red', 'green', 'blue', 'green', 'red'],\n","    'gender': ['female', 'male', 'male', 'female', 'female'],\n","    'price': [199.0, 89.0, 99.0, 129.0, 79.0],\n","    'weight': [500, 450, 300, 380, 410],\n","    'bought': ['yes', 'no', 'yes', 'no', 'yes']\n","}\n","\n","df = pd.DataFrame(data)\n","\n","onehotencoder = OneHotEncoder(sparse_output=False)\n","onehotencoder.fit(df[[\"size\"]])\n","transformed_size = onehotencoder.transform(df[[\"size\"]])\n","\n","print(transformed_size)\n","print(onehotencoder.categories_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Szi7M7rzj6B3","executionInfo":{"status":"ok","timestamp":1714831914375,"user_tz":-120,"elapsed":207,"user":{"displayName":"Cabuxo","userId":"03926967791650024818"}},"outputId":"ae7985e9-4ebe-4ea8-d542-5e9b5f0c2bcd"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]]\n","[array(['L', 'M', 'XL'], dtype=object)]\n"]}]},{"cell_type":"markdown","source":["**Exercise 27**\n","\n","Load Breast Cancer Data using the `load_breast_cancer()` function from the *scikit-learn* package into the *raw_data* variable. Then print information about this dataset to the console (the content of the `'DESCR'` key) as shown below.\n","\n","**Expected result:**\n","\n","```python\n",".. _breast_cancer_dataset:\n","\n","Breast cancer wisconsin (diagnostic) dataset\n","--------------------------------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 569\n","\n","    :Number of Attributes: 30 numeric, predictive attributes and the class\n","\n","    :Attribute Information:\n","        - radius (mean of distances from center to points on the perimeter)\n","        - texture (standard deviation of gray-scale values)\n","        - perimeter\n","        - area\n","        - smoothness (local variation in radius lengths)\n","        - compactness (perimeter^2 / area - 1.0)\n","        - concavity (severity of concave portions of the contour)\n","        - concave points (number of concave portions of the contour)\n","        - symmetry\n","        - fractal dimension (\"coastline approximation\" - 1)\n","\n","        The mean, standard error, and \"worst\" or largest (mean of the three\n","        worst/largest values) of these features were computed for each image,\n","        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n","        10 is Radius SE, field 20 is Worst Radius.\n","\n","        - class:\n","                - WDBC-Malignant\n","                - WDBC-Benign\n","\n","    :Summary Statistics:\n","\n","    ===================================== ====== ======\n","                                           Min    Max\n","    ===================================== ====== ======\n","    radius (mean):                        6.981  28.11\n","    texture (mean):                       9.71   39.28\n","    perimeter (mean):                     43.79  188.5\n","    area (mean):                          143.5  2501.0\n","    smoothness (mean):                    0.053  0.163\n","    compactness (mean):                   0.019  0.345\n","    concavity (mean):                     0.0    0.427\n","    concave points (mean):                0.0    0.201\n","    symmetry (mean):                      0.106  0.304\n","    fractal dimension (mean):             0.05   0.097\n","    radius (standard error):              0.112  2.873\n","    texture (standard error):             0.36   4.885\n","    perimeter (standard error):           0.757  21.98\n","    area (standard error):                6.802  542.2\n","    smoothness (standard error):          0.002  0.031\n","    compactness (standard error):         0.002  0.135\n","    concavity (standard error):           0.0    0.396\n","    concave points (standard error):      0.0    0.053\n","    symmetry (standard error):            0.008  0.079\n","    fractal dimension (standard error):   0.001  0.03\n","    radius (worst):                       7.93   36.04\n","    texture (worst):                      12.02  49.54\n","    perimeter (worst):                    50.41  251.2\n","    area (worst):                         185.2  4254.0\n","    smoothness (worst):                   0.071  0.223\n","    compactness (worst):                  0.027  1.058\n","    concavity (worst):                    0.0    1.252\n","    concave points (worst):               0.0    0.291\n","    symmetry (worst):                     0.156  0.664\n","    fractal dimension (worst):            0.055  0.208\n","    ===================================== ====== ======\n","\n","    :Missing Attribute Values: None\n","\n","    :Class Distribution: 212 - Malignant, 357 - Benign\n","\n","    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n","\n","    :Donor: Nick Street\n","\n","    :Date: November, 1995\n","\n","This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n","https://goo.gl/U2Uwz2\n","\n","Features are computed from a digitized image of a fine needle\n","aspirate (FNA) of a breast mass.  They describe\n","characteristics of the cell nuclei present in the image.\n","\n","Separating plane described above was obtained using\n","Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n","Construction Via Linear Programming.\" Proceedings of the 4th\n","Midwest Artificial Intelligence and Cognitive Science Society,\n","pp. 97-101, 1992], a classification method which uses linear\n","programming to construct a decision tree.  Relevant features\n","were selected using an exhaustive search in the space of 1-4\n","features and 1-3 separating planes.\n","\n","The actual linear program used to obtain the separating plane\n","in the 3-dimensional space is that described in:\n","[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n","Programming Discrimination of Two Linearly Inseparable Sets\",\n","Optimization Methods and Software 1, 1992, 23-34].\n","\n","This database is also available through the UW CS ftp server:\n","\n","ftp ftp.cs.wisc.edu\n","cd math-prog/cpo-dataset/machine-learn/WDBC/\n","\n",".. topic:: References\n","\n","   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\n","     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\n","     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n","     San Jose, CA, 1993.\n","   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\n","     prognosis via linear programming. Operations Research, 43(4), pages 570-577,\n","     July-August 1995.\n","   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n","     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\n","     163-171.        \n","```\n","\n","[Solution 27](https://www.notion.so/Solution-27-37f2e5ec9d1340e08c8af42790acbc6d?pvs=21)"],"metadata":{"id":"jI87oqPXj-Iv"}},{"cell_type":"code","source":["from sklearn import datasets\n","\n","raw_data = datasets.load_breast_cancer()\n","\n","print(raw_data[\"DESCR\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h0-8ZQZpj-oY","executionInfo":{"status":"ok","timestamp":1714832494501,"user_tz":-120,"elapsed":209,"user":{"displayName":"Cabuxo","userId":"03926967791650024818"}},"outputId":"6ee29e0c-42f3-4196-e45d-6389cfc201c6"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":[".. _breast_cancer_dataset:\n","\n","Breast cancer wisconsin (diagnostic) dataset\n","--------------------------------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 569\n","\n","    :Number of Attributes: 30 numeric, predictive attributes and the class\n","\n","    :Attribute Information:\n","        - radius (mean of distances from center to points on the perimeter)\n","        - texture (standard deviation of gray-scale values)\n","        - perimeter\n","        - area\n","        - smoothness (local variation in radius lengths)\n","        - compactness (perimeter^2 / area - 1.0)\n","        - concavity (severity of concave portions of the contour)\n","        - concave points (number of concave portions of the contour)\n","        - symmetry\n","        - fractal dimension (\"coastline approximation\" - 1)\n","\n","        The mean, standard error, and \"worst\" or largest (mean of the three\n","        worst/largest values) of these features were computed for each image,\n","        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n","        10 is Radius SE, field 20 is Worst Radius.\n","\n","        - class:\n","                - WDBC-Malignant\n","                - WDBC-Benign\n","\n","    :Summary Statistics:\n","\n","    ===================================== ====== ======\n","                                           Min    Max\n","    ===================================== ====== ======\n","    radius (mean):                        6.981  28.11\n","    texture (mean):                       9.71   39.28\n","    perimeter (mean):                     43.79  188.5\n","    area (mean):                          143.5  2501.0\n","    smoothness (mean):                    0.053  0.163\n","    compactness (mean):                   0.019  0.345\n","    concavity (mean):                     0.0    0.427\n","    concave points (mean):                0.0    0.201\n","    symmetry (mean):                      0.106  0.304\n","    fractal dimension (mean):             0.05   0.097\n","    radius (standard error):              0.112  2.873\n","    texture (standard error):             0.36   4.885\n","    perimeter (standard error):           0.757  21.98\n","    area (standard error):                6.802  542.2\n","    smoothness (standard error):          0.002  0.031\n","    compactness (standard error):         0.002  0.135\n","    concavity (standard error):           0.0    0.396\n","    concave points (standard error):      0.0    0.053\n","    symmetry (standard error):            0.008  0.079\n","    fractal dimension (standard error):   0.001  0.03\n","    radius (worst):                       7.93   36.04\n","    texture (worst):                      12.02  49.54\n","    perimeter (worst):                    50.41  251.2\n","    area (worst):                         185.2  4254.0\n","    smoothness (worst):                   0.071  0.223\n","    compactness (worst):                  0.027  1.058\n","    concavity (worst):                    0.0    1.252\n","    concave points (worst):               0.0    0.291\n","    symmetry (worst):                     0.156  0.664\n","    fractal dimension (worst):            0.055  0.208\n","    ===================================== ====== ======\n","\n","    :Missing Attribute Values: None\n","\n","    :Class Distribution: 212 - Malignant, 357 - Benign\n","\n","    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n","\n","    :Donor: Nick Street\n","\n","    :Date: November, 1995\n","\n","This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n","https://goo.gl/U2Uwz2\n","\n","Features are computed from a digitized image of a fine needle\n","aspirate (FNA) of a breast mass.  They describe\n","characteristics of the cell nuclei present in the image.\n","\n","Separating plane described above was obtained using\n","Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n","Construction Via Linear Programming.\" Proceedings of the 4th\n","Midwest Artificial Intelligence and Cognitive Science Society,\n","pp. 97-101, 1992], a classification method which uses linear\n","programming to construct a decision tree.  Relevant features\n","were selected using an exhaustive search in the space of 1-4\n","features and 1-3 separating planes.\n","\n","The actual linear program used to obtain the separating plane\n","in the 3-dimensional space is that described in:\n","[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n","Programming Discrimination of Two Linearly Inseparable Sets\",\n","Optimization Methods and Software 1, 1992, 23-34].\n","\n","This database is also available through the UW CS ftp server:\n","\n","ftp ftp.cs.wisc.edu\n","cd math-prog/cpo-dataset/machine-learn/WDBC/\n","\n",".. topic:: References\n","\n","   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n","     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n","     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n","     San Jose, CA, 1993.\n","   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n","     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n","     July-August 1995.\n","   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n","     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n","     163-171.\n"]}]},{"cell_type":"markdown","source":["**Exercise 28**\n","\n","The Breast Cancer Data was loaded into the *raw_data* variable.\n","\n","Assign the value for the `'data'` key (*numpy* array) to the *data* variable. Then assign the value for the `'target'` key (*numpy* array) to the *target* variable*.*\n","\n","In response, print the first three elements of the *data* array to the console.\n","\n","**Expected result:**\n","\n","```python\n","[[  17.99   10.38  122.8  1001.      0.12    0.28    0.3     0.15    0.24    0.08    1.09    0.91\n","     8.59  153.4     0.01    0.05    0.05    0.02    0.03    0.01   25.38   17.33  184.6  2019.\n","     0.16    0.67    0.71    0.27    0.46    0.12]\n"," [  20.57   17.77  132.9  1326.      0.08    0.08    0.09    0.07    0.18    0.06    0.54    0.73\n","     3.4    74.08    0.01    0.01    0.02    0.01    0.01    0.     24.99   23.41  158.8  1956.\n","     0.12    0.19    0.24    0.19    0.28    0.09]\n"," [  19.69   21.25  130.   1203.      0.11    0.16    0.2     0.13    0.21    0.06    0.75    0.79\n","     4.58   94.03    0.01    0.04    0.04    0.02    0.02    0.     23.57   25.53  152.5  1709.\n","     0.14    0.42    0.45    0.24    0.36    0.09]]\n","```\n","\n","[Solution 28](https://www.notion.so/Solution-28-5a202e1047fb4c62bb3827a1872c4e49?pvs=21)"],"metadata":{"id":"PsPRvoRKkgwE"}},{"cell_type":"code","source":["from sklearn import datasets\n","import numpy as np\n","\n","raw_data = datasets.load_breast_cancer()\n","\n","data = raw_data[\"data\"]\n","target = raw_data[\"target\"]\n","\n","np.set_printoptions(precision=2, suppress=True)\n","print(data[:3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsyhpvKDkhBX","executionInfo":{"status":"ok","timestamp":1714832860555,"user_tz":-120,"elapsed":297,"user":{"displayName":"Cabuxo","userId":"03926967791650024818"}},"outputId":"be3e0af0-fc88-4609-b0f4-245fa6584226"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["[[  17.99   10.38  122.8  1001.      0.12    0.28    0.3     0.15    0.24\n","     0.08    1.09    0.91    8.59  153.4     0.01    0.05    0.05    0.02\n","     0.03    0.01   25.38   17.33  184.6  2019.      0.16    0.67    0.71\n","     0.27    0.46    0.12]\n"," [  20.57   17.77  132.9  1326.      0.08    0.08    0.09    0.07    0.18\n","     0.06    0.54    0.73    3.4    74.08    0.01    0.01    0.02    0.01\n","     0.01    0.     24.99   23.41  158.8  1956.      0.12    0.19    0.24\n","     0.19    0.28    0.09]\n"," [  19.69   21.25  130.   1203.      0.11    0.16    0.2     0.13    0.21\n","     0.06    0.75    0.79    4.58   94.03    0.01    0.04    0.04    0.02\n","     0.02    0.     23.57   25.53  152.5  1709.      0.14    0.42    0.45\n","     0.24    0.36    0.09]]\n"]}]},{"cell_type":"markdown","source":["**Exercise 29**\n","\n","The Breast Cancer Data was loaded into the *data* and *target* variables.\n","\n","Combine these two arrays into one array, assign to *all_data* variable and print the first three rows of this array to the console.\n","\n","**Expected result:**\n","\n","```python\n","[[  17.99   10.38  122.8  1001.      0.12    0.28    0.3     0.15    0.24    0.08    1.09    0.91\n","     8.59  153.4     0.01    0.05    0.05    0.02    0.03    0.01   25.38   17.33  184.6  2019.\n","     0.16    0.67    0.71    0.27    0.46    0.12    0.  ]\n"," [  20.57   17.77  132.9  1326.      0.08    0.08    0.09    0.07    0.18    0.06    0.54    0.73\n","     3.4    74.08    0.01    0.01    0.02    0.01    0.01    0.     24.99   23.41  158.8  1956.\n","     0.12    0.19    0.24    0.19    0.28    0.09    0.  ]\n"," [  19.69   21.25  130.   1203.      0.11    0.16    0.2     0.13    0.21    0.06    0.75    0.79\n","     4.58   94.03    0.01    0.04    0.04    0.02    0.02    0.     23.57   25.53  152.5  1709.\n","     0.14    0.42    0.45    0.24    0.36    0.09    0.  ]]\n","```\n","\n","[Solution 29](https://www.notion.so/Solution-29-e1dcd264041f4d9eaa1c9db3707bcbce?pvs=21)"],"metadata":{"id":"zW4si3Vdkjac"}},{"cell_type":"code","source":["from sklearn import datasets\n","import numpy as np\n","\n","raw_data = datasets.load_breast_cancer()\n","\n","data = raw_data[\"data\"]\n","target = raw_data[\"target\"]\n","\n","np.set_printoptions(precision=2, suppress=True)\n","\n","all_data = np.column_stack((data, target))\n","all_data[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6M3KIU9lkjs6","executionInfo":{"status":"ok","timestamp":1714833152032,"user_tz":-120,"elapsed":196,"user":{"displayName":"Cabuxo","userId":"03926967791650024818"}},"outputId":"0fce6e83-f373-4019-c4e5-f1e050821cb2"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  17.99,   10.38,  122.8 , 1001.  ,    0.12,    0.28,    0.3 ,\n","           0.15,    0.24,    0.08,    1.09,    0.91,    8.59,  153.4 ,\n","           0.01,    0.05,    0.05,    0.02,    0.03,    0.01,   25.38,\n","          17.33,  184.6 , 2019.  ,    0.16,    0.67,    0.71,    0.27,\n","           0.46,    0.12,    0.  ],\n","       [  20.57,   17.77,  132.9 , 1326.  ,    0.08,    0.08,    0.09,\n","           0.07,    0.18,    0.06,    0.54,    0.73,    3.4 ,   74.08,\n","           0.01,    0.01,    0.02,    0.01,    0.01,    0.  ,   24.99,\n","          23.41,  158.8 , 1956.  ,    0.12,    0.19,    0.24,    0.19,\n","           0.28,    0.09,    0.  ],\n","       [  19.69,   21.25,  130.  , 1203.  ,    0.11,    0.16,    0.2 ,\n","           0.13,    0.21,    0.06,    0.75,    0.79,    4.58,   94.03,\n","           0.01,    0.04,    0.04,    0.02,    0.02,    0.  ,   23.57,\n","          25.53,  152.5 , 1709.  ,    0.14,    0.42,    0.45,    0.24,\n","           0.36,    0.09,    0.  ]])"]},"metadata":{},"execution_count":72}]},{"cell_type":"markdown","source":["**Exercise 30**\n","\n","The Breast Cancer Data was loaded into the *all_data* variable.\n","\n","Create a *DataFrame* from the *all_data* array and assign to *df* variable. Set column names using value for the key `'feature_names'` of *raw_data* + set target variable name as `'target'` as shown below.\n","\n","In response, print the first five rows of this *DataFrame* to the console.\n","\n","**Expected result:**\n","\n","```python\n"," mean radius  mean texture  mean perimeter  mean area  mean smoothness  ...  worst concavity  worst concave points  worst symmetry  worst fractal dimension  target\n","0        17.99         10.38          122.80     1001.0          0.11840  ...           0.7119                0.2654          0.4601                  0.11890     0.0\n","1        20.57         17.77          132.90     1326.0          0.08474  ...           0.2416                0.1860          0.2750                  0.08902     0.0\n","2        19.69         21.25          130.00     1203.0          0.10960  ...           0.4504                0.2430          0.3613                  0.08758     0.0\n","3        11.42         20.38           77.58      386.1          0.14250  ...           0.6869                0.2575          0.6638                  0.17300     0.0\n","4        20.29         14.34          135.10     1297.0          0.10030  ...           0.4000                0.1625          0.2364                  0.07678     0.0\n","\n","[5 rows x 31 columns]\n","\n","```\n","\n","[Solution 30](https://www.notion.so/Solution-30-208e8346f9464962a519c29194532f4e?pvs=21)"],"metadata":{"id":"wr03KRt0knh-"}},{"cell_type":"code","source":["#ТЗ странное. Непонятно, какая переменная откуда должна выходить.\n","\n","from sklearn import datasets\n","import pandas as pd\n","\n","pd.set_option('display.max_columns', 10)\n","pd.set_option('display.width', 200)\n","np.set_printoptions(precision=2, suppress=True, linewidth=100)\n","raw_data = datasets.load_breast_cancer()\n","\n","data = raw_data['data']\n","target = raw_data['target']\n","\n","all_data = np.c_[data, target]\n","df = pd.DataFrame(\n","    data=all_data,\n","    columns=list(raw_data['feature_names']) + ['target']\n",")\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C-Em-XgEknz2","executionInfo":{"status":"ok","timestamp":1714834460195,"user_tz":-120,"elapsed":218,"user":{"displayName":"Cabuxo","userId":"03926967791650024818"}},"outputId":"3dcfcfc3-0275-487f-ae9d-73565b52c29c"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["   mean radius  mean texture  mean perimeter  mean area  mean smoothness  ...  worst concavity  worst concave points  worst symmetry  worst fractal dimension  target\n","0        17.99         10.38          122.80     1001.0          0.11840  ...           0.7119                0.2654          0.4601                  0.11890     0.0\n","1        20.57         17.77          132.90     1326.0          0.08474  ...           0.2416                0.1860          0.2750                  0.08902     0.0\n","2        19.69         21.25          130.00     1203.0          0.10960  ...           0.4504                0.2430          0.3613                  0.08758     0.0\n","3        11.42         20.38           77.58      386.1          0.14250  ...           0.6869                0.2575          0.6638                  0.17300     0.0\n","4        20.29         14.34          135.10     1297.0          0.10030  ...           0.4000                0.1625          0.2364                  0.07678     0.0\n","\n","[5 rows x 31 columns]\n"]}]},{"cell_type":"markdown","source":["**Exercise 31**\n","\n","The Breast Cancer Data was loaded into the *data* and *target* variables.\n","\n","Using the `train_test_split()` function from the *scikit-learn* package, split the data (*data* and *target*) into train and test sets:\n","\n","- train set: `X_train, y_train`\n","- test set: `X_test, y_test`\n","\n","Set the `random_state=40` and the test set size to 25%.\n","\n","In response, print the shapes of these arrays to the console as shown below.\n","\n","```python\n","X_train shape (426, 30)\n","y_train shape (426,)\n","X_test shape (143, 30)\n","y_test shape (143,)\n","```\n","\n","[Solution 31](https://www.notion.so/Solution-31-d5259ff6894848d0ba16c3b79e96a4d4?pvs=21)"],"metadata":{"id":"URy-hJuTkuRp"}},{"cell_type":"code","source":["from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","\n","data, target = datasets.load_breast_cancer(return_X_y=True)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    data,\n","    target,\n","    test_size=0.25,\n","    random_state=40)\n","\n","print(\"X_train shape {}\".format(X_train.shape))\n","print(\"y_train shape {}\".format(y_train.shape))\n","print(\"X_test shape {}\".format(X_test.shape))\n","print(\"y_test shape {}\".format(y_test.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTwFnnoZkug2","executionInfo":{"status":"ok","timestamp":1714834777528,"user_tz":-120,"elapsed":3,"user":{"displayName":"Cabuxo","userId":"03926967791650024818"}},"outputId":"0f92cc71-029c-441e-8af6-f7a6de8e41f6"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape (426, 30)\n","y_train shape (426,)\n","X_test shape (143, 30)\n","y_test shape (143,)\n"]}]}]}